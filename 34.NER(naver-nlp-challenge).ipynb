{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Embeddings\n",
    "    word_embedding_dim = 128\n",
    "    char_embedding_dim = 128\n",
    "    \n",
    "    # RNN\n",
    "    hidden_size_word = 128\n",
    "    hidden_size_char = 128\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 64\n",
    "    num_epochs = 20\n",
    "    display_every = 500\n",
    "    evaluate_every = 1000\n",
    "    num_checkpoints = 5\n",
    "    decay_rate = 0.9\n",
    "    \n",
    "    learning_rate = 1.0 \n",
    "    decay_rate = 0.95\n",
    "    \n",
    "    # Testing parameters\n",
    "    checkpoint_dir = ''\n",
    "    \n",
    "    UNK = \"$UNK$\"\n",
    "    NUM = \"$NUM$\"\n",
    "    NONE = \"-\"\n",
    "    PAD = '$PAD$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "nlp-challenge NER dataset: https://github.com/naver/nlp-challenge/tree/master/missions/ner\n",
    "\n",
    "LeaderBoard and Tag description: http://air.changwon.ac.kr/?page_id=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER_B DAT_B - ORG_B CVL_B - - - - -</td>\n",
       "      <td>비토리오 양일 만에 영사관 감호 용퇴, 항룡 압력설 의심만 가율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- - - NUM_B NUM_B -</td>\n",
       "      <td>이 음경동맥의 직경이 $NUM$ 19mm입니다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NUM_B - NUM_B ORG_B PER_B - NUM_B - - NUM_B - ...</td>\n",
       "      <td>9세이브로 구완 30위인 lg 박찬형은 평균자책점이 16.45로 준수한 편이지만 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUM_B NUM_B LOC_B - EVT_B - - - - -</td>\n",
       "      <td>7승 25패는 상트페테르부르크가 역대 월드리그에 출진한 분별 최선의 성적이다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- PER_B CVL_B -</td>\n",
       "      <td>▲ 퍼거슨 씨족의 꾀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EVT_B CVL_B - - CVL_B - - - -</td>\n",
       "      <td>[유로2008] '공인구가 변할 기록 시정조치는 죽을 맛 ? '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EVT_B TRM_B TRM_I CVL_B - PER_B DAT_B EVT_B EV...</td>\n",
       "      <td>로마올림픽에서 육미지황탕 이남지역으로 동메달에 머문 추경대는 차년 파리오픈 결승전에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>- CVL_B CVL_I NUM_B NUM_I DAT_B TIM_B TIM_I TI...</td>\n",
       "      <td>금반 명기 통합우승 24, 10회차는 8일 상오 6시 50분, 상오 11시 50분에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>- - - - - - -</td>\n",
       "      <td>권뢰가 있는 곳에 직경에 따라 달라지는데요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>- - - - - - -</td>\n",
       "      <td>때로는은 귀여운 가스나기인 비담, 세상일에는 무관심 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0                PER_B DAT_B - ORG_B CVL_B - - - - -   \n",
       "1                                - - - NUM_B NUM_B -   \n",
       "2  NUM_B - NUM_B ORG_B PER_B - NUM_B - - NUM_B - ...   \n",
       "3                NUM_B NUM_B LOC_B - EVT_B - - - - -   \n",
       "4                                    - PER_B CVL_B -   \n",
       "5                      EVT_B CVL_B - - CVL_B - - - -   \n",
       "6  EVT_B TRM_B TRM_I CVL_B - PER_B DAT_B EVT_B EV...   \n",
       "7  - CVL_B CVL_I NUM_B NUM_I DAT_B TIM_B TIM_I TI...   \n",
       "8                                      - - - - - - -   \n",
       "9                                      - - - - - - -   \n",
       "\n",
       "                                               words  \n",
       "0                비토리오 양일 만에 영사관 감호 용퇴, 항룡 압력설 의심만 가율  \n",
       "1                        이 음경동맥의 직경이 $NUM$ 19mm입니다 .  \n",
       "2  9세이브로 구완 30위인 lg 박찬형은 평균자책점이 16.45로 준수한 편이지만 2...  \n",
       "3       7승 25패는 상트페테르부르크가 역대 월드리그에 출진한 분별 최선의 성적이다 .  \n",
       "4                                        ▲ 퍼거슨 씨족의 꾀  \n",
       "5                [유로2008] '공인구가 변할 기록 시정조치는 죽을 맛 ? '  \n",
       "6  로마올림픽에서 육미지황탕 이남지역으로 동메달에 머문 추경대는 차년 파리오픈 결승전에...  \n",
       "7  금반 명기 통합우승 24, 10회차는 8일 상오 6시 50분, 상오 11시 50분에...  \n",
       "8                          권뢰가 있는 곳에 직경에 따라 달라지는데요 .  \n",
       "9                     때로는은 귀여운 가스나기인 비담, 세상일에는 무관심 .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.all_tags, self.all_words, self.all_chars = [], [], []\n",
    "        \n",
    "    def processing_word(self, word):\n",
    "        word = word.lower()\n",
    "        if word.isdigit():\n",
    "            word = Config.NUM\n",
    "        return word\n",
    "        \n",
    "    def load_dataset(self, path):\n",
    "        words_col, tags_col = [], []\n",
    "        with open(path) as f:\n",
    "            words, tags = [], []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if len(line) == 0:\n",
    "                    if len(words) != 0:\n",
    "                        words_col.append(' '.join(words))\n",
    "                        tags_col.append(' '.join(tags))\n",
    "                        words, tags = [], []\n",
    "                else:\n",
    "                    ls = line.split('\\t')\n",
    "                    word, tag = ls[1], ls[2]\n",
    "                    word = self.processing_word(word)\n",
    "                    \n",
    "                    words.append(word)\n",
    "                    tags.append(tag)\n",
    "                    \n",
    "                    self.all_words.append(word)\n",
    "                    self.all_tags.append(tag)\n",
    "                    self.all_chars.extend(list(word))\n",
    "                    \n",
    "                    \n",
    "        return pd.DataFrame({'words': words_col, 'tags': tags_col})\n",
    "        \n",
    "    def download_and_load_datasets(self):\n",
    "        self.all_tags, self.all_words = [], [] \n",
    "        \n",
    "        dataset = tf.keras.utils.get_file(\n",
    "          fname=\"naver_challenge_ner_train_data.zip\", \n",
    "          origin=\"https://s3.ap-northeast-2.amazonaws.com/bowbowbow-storage/dataset/naver_challenge_ner_train_data.zip\", \n",
    "          extract=True)\n",
    "\n",
    "        train_df = self.load_dataset(os.path.join(os.path.dirname(dataset), 'naver_challenge_ner_train_data'))\n",
    "        return train_df\n",
    "\n",
    "dataset = Dataset()\n",
    "df = dataset.download_and_load_datasets()\n",
    "\n",
    "# shuffle \n",
    "shuffle_indices = np.random.permutation(np.arange(len(df)))\n",
    "shuffled_df= df.iloc[shuffle_indices]\n",
    "\n",
    "train_end = int(len(df) * 0.9)\n",
    "\n",
    "train_df = df.iloc[:train_end]\n",
    "dev_df = df.iloc[train_end:]\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(dataset.all_words)) + [Config.PAD, Config.UNK]\n",
    "word2idx = {w: i for i, w in enumerate(word_list)}\n",
    "idx2word = {i: w for i, w in enumerate(word_list)}\n",
    "\n",
    "tag_list = list(set(dataset.all_tags))\n",
    "tag2idx = {w: i for i, w in enumerate(tag_list)}\n",
    "idx2tag = {i: w for i, w in enumerate(tag_list)}\n",
    "\n",
    "char_list = list(set(dataset.all_chars)) + [Config.PAD, Config.UNK]\n",
    "char2idx = {w: i for i, w in enumerate(char_list)}\n",
    "idx2char = {i: w for i, w in enumerate(char_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, \n",
    "               num_classes, \n",
    "               vocab_size, \n",
    "               char_size,\n",
    "               word_embedding_dim, \n",
    "               char_embedding_dim,\n",
    "               hidden_size_word,\n",
    "               hidden_size_char):\n",
    "        \n",
    "        self.word_ids = tf.placeholder(tf.int32, shape=[None, None], name='word_ids') \n",
    "        self.sequence_lengths = tf.placeholder(tf.int32, shape=[None], name=\"sequence_lengths\")\n",
    "        \n",
    "        self.labels = tf.placeholder(tf.int32, shape=[None, None], name='labels')\n",
    "        \n",
    "        self.char_ids = tf.placeholder(tf.int32, shape=[None, None, None], name='char_ids') # [batch_size, max_sequence_length, max_word_length]\n",
    "        self.word_lengths = tf.placeholder(tf.int32, shape=[None, None], name=\"word_lengths\") # [batch_size, max_sequence_length]\n",
    "        \n",
    "        self.dropout = tf.placeholder(dtype=tf.float32, shape=[],name=\"dropout\")\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        # Word Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.variable_scope('word-embedding'):\n",
    "            self._word_embeddings = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim], -0.25, 0.25), name='_word_embeddings')\n",
    "            self.word_embeddings = tf.nn.embedding_lookup(self._word_embeddings, self.word_ids) # [batch_size, max_sequence_length, word_embedding_dim]\n",
    "        \n",
    "        # Char Embedding Layer\n",
    "        with tf.variable_scope('char-embedding'):\n",
    "            self._char_embeddings = tf.get_variable(dtype=tf.float32, shape=[char_size, char_embedding_dim], name='_char_embeddings')\n",
    "            \n",
    "            # [batch_size, max_sequence_length, max_word_length, char_embedding_dim]\n",
    "            self.char_embeddings = tf.nn.embedding_lookup(self._char_embeddings, self.char_ids) \n",
    "            \n",
    "            s = tf.shape(self.char_embeddings)\n",
    "            \n",
    "            # [batch_size*max_sequence_length, max_word_length, char_embedding_dim]\n",
    "            char_embeddings = tf.reshape(self.char_embeddings, shape=[s[0]*s[1], s[2], char_embedding_dim])\n",
    "            word_lengths = tf.reshape(self.word_lengths, shape=[-1])\n",
    "            \n",
    "            fw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size_char, state_is_tuple=True)\n",
    "            bw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size_char, state_is_tuple=True)\n",
    "            \n",
    "            _, ((_, output_fw), (_, output_bw)) = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_cell, \n",
    "                                                                                   cell_bw=bw_cell, \n",
    "                                                                                   inputs=char_embeddings,\n",
    "                                                                                   sequence_length=word_lengths,\n",
    "                                                                                   dtype=tf.float32)\n",
    "            # shape: [batch_size*max_sequnce_length, 2*hidden_size_char]\n",
    "            output = tf.concat([output_fw, output_bw], axis=-1)\n",
    "            output = tf.reshape(output, shape=[s[0], s[1], 2*hidden_size_char])\n",
    "            \n",
    "            # shape: # [batch_size, max_sequence_length, word_embedding_dim + 2*hidden_size_char]\n",
    "            self.word_embeddings = tf.concat([self.word_embeddings, output], axis=-1) \n",
    "            # self.word_embeddings = tf.nn.dropout(self.word_embeddings, self.dropout)\n",
    "            \n",
    "        # Bidirectional LSTM\n",
    "        with tf.variable_scope(\"bi-lstm\"):\n",
    "            fw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size_word)\n",
    "            bw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size_word)\n",
    "            (output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_cell,\n",
    "                                                                  cell_bw=bw_cell,\n",
    "                                                                  inputs=self.word_embeddings,\n",
    "                                                                  sequence_length= self.sequence_lengths, # [batch_size],\n",
    "                                                                  dtype=tf.float32)\n",
    "            \n",
    "            self.rnn_outputs = tf.concat([output_fw, output_bw], axis=-1)  # [batch_size, max_sequence_length, 2*hidden_size_word]\n",
    "            self.rnn_outputs = tf.nn.dropout(self.rnn_outputs, self.dropout)\n",
    "        \n",
    "        \n",
    "        # Fully connected layer\n",
    "        with tf.variable_scope('output'):\n",
    "            self.W_output = tf.get_variable('W_output', shape=[2*hidden_size_word, num_classes],  dtype=tf.float32)\n",
    "            self.b_output = tf.get_variable('b_output', shape=[num_classes], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "            \n",
    "            nsteps = tf.shape(self.rnn_outputs)[1]\n",
    "            rnn_outputs_flat = tf.reshape(self.rnn_outputs, [-1, 2*hidden_size_word])\n",
    "            pred = tf.matmul(rnn_outputs_flat, self.W_output) + self.b_output\n",
    "            \n",
    "            self.logits = tf.reshape(pred, [-1, nsteps, num_classes]) # [batch_size, max_sequence_length, num_classes]\n",
    "    \n",
    "        # Calculate mean corss-entropy loss\n",
    "        with tf.variable_scope('loss'):\n",
    "            log_likelihood, trans_params = tf.contrib.crf.crf_log_likelihood(self.logits, self.labels, self.sequence_lengths)\n",
    "            self.trans_params = trans_params  # need to evaluate it for decoding\n",
    "            self.loss = tf.reduce_mean(-log_likelihood)\n",
    "            \n",
    "#             When CRF is not in use\n",
    "#             self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels)\n",
    "#             mask = tf.sequence_mask(self.sequence_lengths)\n",
    "#             losses = tf.boolean_mask(self.losses, mask)\n",
    "#             self.loss = tf.reduce_mean(losses) \n",
    "        \n",
    "    # Length of the sequence data\n",
    "    @staticmethod\n",
    "    def _length(seq):\n",
    "        relevant = tf.sign(tf.abs(seq))\n",
    "        length = tf.reduce_sum(relevant, reduction_indices=1)\n",
    "        length = tf.cast(length, tf.int32)\n",
    "        return length\n",
    "    \n",
    "    @staticmethod\n",
    "    def viterbi_decode(logits, trans_params):\n",
    "        # get tag scores and transition params of CRF\n",
    "        viterbi_sequences = []\n",
    "\n",
    "        # iterate over the sentences because no batching in vitervi_decode\n",
    "        for logit, sequence_length in zip(logits, sequence_lengths):\n",
    "            logit = logit[:sequence_length]  # keep only the valid steps\n",
    "            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(\n",
    "                logit, trans_params)\n",
    "            viterbi_sequences += [viterbi_seq]\n",
    "\n",
    "        return np.array(viterbi_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained glove\n",
    "def load_glove(word_embedding_dim, word2idx):\n",
    "    download_path = tf.keras.utils.get_file(\n",
    "      fname=\"glove.6B.zip\", \n",
    "      origin=\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "      extract=True)\n",
    "    \n",
    "    embedding_path = os.path.join(os.path.dirname(download_path), 'glove.6B.300d.txt')\n",
    "    print('embedding_path :', embedding_path)\n",
    "\n",
    "    # initial matrix with random uniform\n",
    "    initW = np.random.randn(len(word2idx), word_embedding_dim).astype(np.float32) / np.sqrt(len(word2idx))\n",
    "    # load any vectors from the glove\n",
    "    print(\"Load glove file {0}\".format(embedding_path))\n",
    "    f = open(embedding_path, 'r', encoding='utf8')\n",
    "    for line in f:\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        if word in word2idx:\n",
    "            initW[word2idx[word]] = embedding\n",
    "    return initW\n",
    "\n",
    "def batch_iter(df, batch_size, num_epochs, shuffle=True, tqdm_disable=False):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data_size = len(df)\n",
    "    num_batches_per_epoch = int((data_size - 1) / batch_size) + 1\n",
    "    for epoch in tqdm(range(num_epochs), disable=tqdm_disable):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_df= df.iloc[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_df = df\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_df.iloc[start_index:end_index]    \n",
    "            \n",
    "\n",
    "def get_feed_dict(batch_df):\n",
    "    max_length = max(map(lambda x : len(x.split(' ')), batch_df['words'].tolist()))\n",
    "    \n",
    "    max_length_word = 0\n",
    "    for seq in batch_df['words'].tolist():\n",
    "        for word in seq.split(' '):\n",
    "            max_length_word = max(max_length_word, len(word))\n",
    "    \n",
    "    word_ids, sequence_lengths, labels, char_ids, word_lengths = [], [], [], [], []\n",
    "    for index, row in batch_df.iterrows():\n",
    "        sentence = row['words'].split(' ')\n",
    "        tags = row['tags'].split(' ')\n",
    "\n",
    "        word_ids_row, labels_row, char_ids_row, word_lengths_row = [], [], [], []\n",
    "        for word in sentence:\n",
    "            word_ids_row.append(word2idx[word])\n",
    "        \n",
    "            char_ids_row.append([char2idx[char] for char in word] + [char2idx[Config.PAD]]* (max_length_word - len(word)) )\n",
    "            word_lengths_row.append(len(word))\n",
    "        \n",
    "        empty_char_ids = [char2idx[Config.PAD]]* max_length_word\n",
    "        char_ids_row += [empty_char_ids] * (max_length - len(char_ids_row))\n",
    "        word_lengths_row += [0] * (max_length - len(word_lengths_row))\n",
    "        \n",
    "        for tag in tags:\n",
    "            labels_row.append(tag2idx[tag])\n",
    "\n",
    "        if len(sentence) < max_length:\n",
    "            word_ids_row += [word2idx[Config.PAD]]* (max_length - len(sentence))\n",
    "            labels_row += [tag2idx[Config.NONE]]* (max_length - len(sentence))\n",
    "\n",
    "        word_ids.append(word_ids_row)\n",
    "        labels.append(labels_row)\n",
    "        sequence_lengths.append(len(sentence))\n",
    "        char_ids.append(char_ids_row)\n",
    "        word_lengths.append(word_lengths_row)\n",
    "    \n",
    "    word_ids = np.array(word_ids)\n",
    "    labels = np.array(labels)\n",
    "    sequence_lengths = np.array(sequence_lengths)\n",
    "    char_ids = np.array(char_ids)\n",
    "    word_lengths = np.array(word_lengths)\n",
    "    \n",
    "    return word_ids, labels, sequence_lengths, char_ids, word_lengths\n",
    "\n",
    "def get_chunks(seq):\n",
    "    \"\"\"Given a sequence of tags, group entities and their position\n",
    "    Example:\n",
    "        seq = [\"B-PER\", \"I-PER\", \"O\", \"B-LOC\"]\n",
    "        result = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_chunk_type(tok):\n",
    "        tag_type = tok.split('_')[0]\n",
    "        tag_class = tok.split('_')[-1]\n",
    "        return tag_class, tag_type\n",
    "\n",
    "    default = Config.NONE\n",
    "    chunks = []\n",
    "    chunk_type, chunk_start = None, None\n",
    "    for i, tok in enumerate(seq):\n",
    "        # End of a chunk 1\n",
    "        if tok == default and chunk_type is not None:\n",
    "            # Add a chunk.\n",
    "            chunk = (chunk_type, chunk_start, i)\n",
    "            chunks.append(chunk)\n",
    "            chunk_type, chunk_start = None, None\n",
    "        # End of a chunk + start of a chunk!\n",
    "        elif tok != default:\n",
    "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok)\n",
    "            if chunk_type is None:\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
    "                chunk = (chunk_type, chunk_start, i)\n",
    "                chunks.append(chunk)\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # end condition\n",
    "    if chunk_type is not None:\n",
    "        chunk = (chunk_type, chunk_start, len(seq))\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def evaluation(y, preds, lengths):\n",
    "    from sklearn.metrics import classification_report\n",
    "    arg_answers, arg_preds = [], []\n",
    "    \n",
    "    accs = []\n",
    "    correct_preds, total_correct, total_preds = 0.0, 0.0, 0.0\n",
    "    for i in range(len(y)):\n",
    "        sent_answers = []\n",
    "        sent_preds = []\n",
    "        for j in range(lengths[i]):\n",
    "            sent_answers.append(idx2tag[y[i][j]])\n",
    "            sent_preds.append(idx2tag[preds[i][j]])\n",
    "    \n",
    "        arg_answers.extend(sent_answers)\n",
    "        arg_preds.extend(sent_preds)\n",
    "        \n",
    "        accs += [a == b for (a, b) in zip(sent_answers, sent_preds)]\n",
    "        \n",
    "        sent_answer_chunks = set(get_chunks(sent_answers))\n",
    "        sent_pred_chunks = set(get_chunks(sent_preds))\n",
    "\n",
    "        correct_preds += len(sent_answer_chunks & sent_pred_chunks)\n",
    "        total_preds += len(sent_pred_chunks)\n",
    "        total_correct += len(sent_answer_chunks)\n",
    "    \n",
    "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
    "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
    "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "    acc = np.mean(accs)\n",
    "        \n",
    "    print(classification_report(arg_answers, arg_preds))\n",
    "    \n",
    "    print('Chunk based evaluation: acc: {}, f1: {}'.format(acc, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/seungwon/project/tf-notes/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-fcaea53ca57f>:41: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-fcaea53ca57f>:48: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/seungwon/project/tf-notes/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/seungwon/project/tf-notes/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-fcaea53ca57f>:55: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungwon/project/tf-notes/venv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/seungwon/project/tf-notes/34.runs/1559116781\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:01:31.740417: step 500, loss 6.67133\n",
      "2019-05-29T17:03:13.592972: step 1000, loss 8.15631\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:03:25.659224: loss 0.0983946\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.91      0.95      0.93     73225\n",
      "       AFW_B       0.75      0.03      0.06       449\n",
      "       AFW_I       0.00      0.00      0.00       175\n",
      "       ANM_B       0.77      0.20      0.32       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.46      0.59      0.52      5612\n",
      "       CVL_I       0.12      0.03      0.05       328\n",
      "       DAT_B       0.90      0.77      0.83      2587\n",
      "       DAT_I       0.82      0.74      0.78       863\n",
      "       EVT_B       0.65      0.46      0.54      1130\n",
      "       EVT_I       0.51      0.47      0.49       729\n",
      "       FLD_B       0.00      0.00      0.00       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.52      0.35      0.42      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.85      0.90      0.88      5569\n",
      "       NUM_I       0.69      0.56      0.62       833\n",
      "       ORG_B       0.58      0.56      0.57      4251\n",
      "       ORG_I       0.25      0.28      0.26       474\n",
      "       PER_B       0.65      0.63      0.64      4263\n",
      "       PER_I       0.48      0.34      0.39       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.81      0.48      0.60       341\n",
      "       TIM_I       0.78      0.73      0.75        91\n",
      "       TRM_B       0.62      0.37      0.46      1965\n",
      "       TRM_I       0.21      0.10      0.13       320\n",
      "\n",
      "   micro avg       0.83      0.83      0.83    106858\n",
      "   macro avg       0.44      0.34      0.37    106858\n",
      "weighted avg       0.82      0.83      0.82    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8330681839450486, f1: 0.5781786030061892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [04:39<1:28:34, 279.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:05:12.469570: step 1500, loss 6.05446\n",
      "2019-05-29T17:06:58.304487: step 2000, loss 5.27416\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:07:10.316027: loss 0.0780885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.91      0.96      0.94     73225\n",
      "       AFW_B       0.49      0.12      0.20       449\n",
      "       AFW_I       0.12      0.03      0.05       175\n",
      "       ANM_B       0.76      0.30      0.43       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.67      0.50      0.57      5612\n",
      "       CVL_I       0.31      0.05      0.08       328\n",
      "       DAT_B       0.91      0.85      0.88      2587\n",
      "       DAT_I       0.85      0.80      0.83       863\n",
      "       EVT_B       0.69      0.63      0.66      1130\n",
      "       EVT_I       0.60      0.61      0.61       729\n",
      "       FLD_B       0.60      0.01      0.03       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.55      0.56      0.55      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.91      0.91      0.91      5569\n",
      "       NUM_I       0.70      0.67      0.68       833\n",
      "       ORG_B       0.62      0.71      0.66      4251\n",
      "       ORG_I       0.38      0.40      0.39       474\n",
      "       PER_B       0.76      0.68      0.72      4263\n",
      "       PER_I       0.56      0.57      0.57       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.83      0.76      0.79       341\n",
      "       TIM_I       0.83      0.86      0.84        91\n",
      "       TRM_B       0.73      0.40      0.52      1965\n",
      "       TRM_I       0.26      0.22      0.24       320\n",
      "\n",
      "   micro avg       0.86      0.86      0.86    106858\n",
      "   macro avg       0.50      0.41      0.43    106858\n",
      "weighted avg       0.85      0.86      0.85    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8618259746579573, f1: 0.6542289910252923\n",
      "2019-05-29T17:08:56.936560: step 2500, loss 5.83968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [09:21<1:24:03, 280.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:10:41.451724: step 3000, loss 4.7216\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:10:53.452052: loss 0.0692763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.92      0.97      0.94     73225\n",
      "       AFW_B       0.47      0.17      0.25       449\n",
      "       AFW_I       0.30      0.18      0.22       175\n",
      "       ANM_B       0.76      0.36      0.49       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.67      0.57      0.62      5612\n",
      "       CVL_I       0.32      0.13      0.18       328\n",
      "       DAT_B       0.92      0.88      0.90      2587\n",
      "       DAT_I       0.88      0.81      0.84       863\n",
      "       EVT_B       0.75      0.67      0.71      1130\n",
      "       EVT_I       0.63      0.64      0.64       729\n",
      "       FLD_B       0.65      0.10      0.17       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.70      0.51      0.59      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.92      0.92      0.92      5569\n",
      "       NUM_I       0.81      0.64      0.72       833\n",
      "       ORG_B       0.74      0.69      0.71      4251\n",
      "       ORG_I       0.48      0.45      0.46       474\n",
      "       PER_B       0.74      0.75      0.75      4263\n",
      "       PER_I       0.53      0.69      0.60       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.86      0.80      0.83       341\n",
      "       TIM_I       0.90      0.79      0.84        91\n",
      "       TRM_B       0.78      0.42      0.55      1965\n",
      "       TRM_I       0.33      0.26      0.29       320\n",
      "\n",
      "   micro avg       0.87      0.87      0.87    106858\n",
      "   macro avg       0.54      0.44      0.47    106858\n",
      "weighted avg       0.87      0.87      0.87    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8747683842108218, f1: 0.6926383273230612\n",
      "2019-05-29T17:12:41.400392: step 3500, loss 4.53747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [14:03<1:19:32, 280.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:14:27.579719: step 4000, loss 4.80876\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:14:39.858569: loss 0.0641514\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.92      0.97      0.94     73225\n",
      "       AFW_B       0.57      0.23      0.33       449\n",
      "       AFW_I       0.26      0.21      0.23       175\n",
      "       ANM_B       0.70      0.45      0.55       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.72      0.56      0.63      5612\n",
      "       CVL_I       0.40      0.21      0.27       328\n",
      "       DAT_B       0.92      0.90      0.91      2587\n",
      "       DAT_I       0.87      0.86      0.86       863\n",
      "       EVT_B       0.80      0.69      0.74      1130\n",
      "       EVT_I       0.74      0.64      0.68       729\n",
      "       FLD_B       0.66      0.20      0.30       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.68      0.61      0.64      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.92      0.92      0.92      5569\n",
      "       NUM_I       0.79      0.69      0.74       833\n",
      "       ORG_B       0.80      0.68      0.74      4251\n",
      "       ORG_I       0.58      0.50      0.54       474\n",
      "       PER_B       0.81      0.72      0.76      4263\n",
      "       PER_I       0.60      0.65      0.62       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.84      0.86      0.85       341\n",
      "       TIM_I       0.89      0.87      0.88        91\n",
      "       TRM_B       0.69      0.55      0.61      1965\n",
      "       TRM_I       0.34      0.33      0.33       320\n",
      "\n",
      "   micro avg       0.88      0.88      0.88    106858\n",
      "   macro avg       0.55      0.48      0.50    106858\n",
      "weighted avg       0.87      0.88      0.88    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8833217915364315, f1: 0.7149643705463183\n",
      "2019-05-29T17:16:24.875634: step 4500, loss 4.27851\n",
      "2019-05-29T17:18:13.781524: step 5000, loss 3.97668\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:18:25.668231: loss 0.0600137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.93      0.97      0.95     73225\n",
      "       AFW_B       0.65      0.28      0.39       449\n",
      "       AFW_I       0.46      0.22      0.30       175\n",
      "       ANM_B       0.76      0.45      0.57       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.74      0.58      0.65      5612\n",
      "       CVL_I       0.29      0.32      0.30       328\n",
      "       DAT_B       0.94      0.89      0.91      2587\n",
      "       DAT_I       0.88      0.87      0.88       863\n",
      "       EVT_B       0.79      0.73      0.76      1130\n",
      "       EVT_I       0.65      0.76      0.70       729\n",
      "       FLD_B       0.66      0.23      0.34       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.72      0.62      0.67      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.92      0.93      5569\n",
      "       NUM_I       0.77      0.72      0.75       833\n",
      "       ORG_B       0.81      0.72      0.76      4251\n",
      "       ORG_I       0.59      0.53      0.56       474\n",
      "       PER_B       0.80      0.76      0.78      4263\n",
      "       PER_I       0.59      0.69      0.64       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.89      0.84      0.86       341\n",
      "       TIM_I       0.83      0.89      0.86        91\n",
      "       TRM_B       0.69      0.58      0.63      1965\n",
      "       TRM_I       0.30      0.33      0.31       320\n",
      "\n",
      "   micro avg       0.89      0.89      0.89    106858\n",
      "   macro avg       0.56      0.50      0.52    106858\n",
      "weighted avg       0.88      0.89      0.88    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8896105111456325, f1: 0.7302712924576332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [18:56<1:15:53, 284.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:20:12.441632: step 5500, loss 4.00884\n",
      "2019-05-29T17:21:57.656629: step 6000, loss 4.17374\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:22:09.654462: loss 0.0571608\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.93      0.97      0.95     73225\n",
      "       AFW_B       0.60      0.33      0.42       449\n",
      "       AFW_I       0.29      0.34      0.31       175\n",
      "       ANM_B       0.78      0.48      0.59       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.72      0.65      0.69      5612\n",
      "       CVL_I       0.39      0.23      0.29       328\n",
      "       DAT_B       0.94      0.90      0.92      2587\n",
      "       DAT_I       0.91      0.84      0.87       863\n",
      "       EVT_B       0.80      0.74      0.77      1130\n",
      "       EVT_I       0.71      0.75      0.73       729\n",
      "       FLD_B       0.70      0.23      0.35       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.76      0.62      0.69      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.93      0.93      5569\n",
      "       NUM_I       0.75      0.74      0.74       833\n",
      "       ORG_B       0.81      0.74      0.77      4251\n",
      "       ORG_I       0.55      0.59      0.57       474\n",
      "       PER_B       0.80      0.78      0.79      4263\n",
      "       PER_I       0.60      0.71      0.65       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.88      0.88      0.88       341\n",
      "       TIM_I       0.91      0.87      0.89        91\n",
      "       TRM_B       0.76      0.55      0.64      1965\n",
      "       TRM_I       0.39      0.41      0.40       320\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    106858\n",
      "   macro avg       0.57      0.51      0.53    106858\n",
      "weighted avg       0.89      0.90      0.89    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8950102004529376, f1: 0.7435038770795652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [23:37<1:10:51, 283.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:23:56.618673: step 6500, loss 3.90478\n",
      "2019-05-29T17:25:42.521636: step 7000, loss 3.65403\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:25:54.708375: loss 0.0550934\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.93      0.97      0.95     73225\n",
      "       AFW_B       0.67      0.33      0.44       449\n",
      "       AFW_I       0.46      0.29      0.36       175\n",
      "       ANM_B       0.80      0.44      0.57       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.75      0.65      0.70      5612\n",
      "       CVL_I       0.37      0.29      0.32       328\n",
      "       DAT_B       0.95      0.90      0.92      2587\n",
      "       DAT_I       0.89      0.88      0.89       863\n",
      "       EVT_B       0.81      0.74      0.77      1130\n",
      "       EVT_I       0.72      0.75      0.73       729\n",
      "       FLD_B       0.66      0.28      0.39       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.79      0.64      0.71      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.94      0.94      5569\n",
      "       NUM_I       0.77      0.73      0.75       833\n",
      "       ORG_B       0.82      0.76      0.79      4251\n",
      "       ORG_I       0.54      0.60      0.57       474\n",
      "       PER_B       0.84      0.77      0.80      4263\n",
      "       PER_I       0.67      0.68      0.67       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.90      0.85      0.87       341\n",
      "       TIM_I       0.88      0.88      0.88        91\n",
      "       TRM_B       0.69      0.62      0.65      1965\n",
      "       TRM_I       0.30      0.44      0.36       320\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    106858\n",
      "   macro avg       0.58      0.52      0.54    106858\n",
      "weighted avg       0.89      0.90      0.89    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.8983978738138464, f1: 0.7550928672887786\n",
      "2019-05-29T17:27:40.605017: step 7500, loss 3.45164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [28:18<1:05:59, 282.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:29:29.221401: step 8000, loss 3.44384\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:29:41.505034: loss 0.0527926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.94      0.97      0.96     73225\n",
      "       AFW_B       0.68      0.37      0.48       449\n",
      "       AFW_I       0.68      0.34      0.46       175\n",
      "       ANM_B       0.80      0.50      0.61       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.77      0.66      0.71      5612\n",
      "       CVL_I       0.52      0.30      0.38       328\n",
      "       DAT_B       0.94      0.92      0.93      2587\n",
      "       DAT_I       0.88      0.90      0.89       863\n",
      "       EVT_B       0.79      0.76      0.78      1130\n",
      "       EVT_I       0.72      0.76      0.74       729\n",
      "       FLD_B       0.71      0.30      0.42       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.74      0.71      0.72      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.94      0.94      5569\n",
      "       NUM_I       0.76      0.76      0.76       833\n",
      "       ORG_B       0.79      0.80      0.79      4251\n",
      "       ORG_I       0.56      0.57      0.57       474\n",
      "       PER_B       0.82      0.80      0.81      4263\n",
      "       PER_I       0.65      0.71      0.68       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.89      0.88      0.88       341\n",
      "       TIM_I       0.86      0.91      0.88        91\n",
      "       TRM_B       0.73      0.62      0.67      1965\n",
      "       TRM_I       0.39      0.45      0.42       320\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    106858\n",
      "   macro avg       0.59      0.53      0.55    106858\n",
      "weighted avg       0.90      0.90      0.90    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9037039809841098, f1: 0.7649167417139023\n",
      "2019-05-29T17:31:27.489952: step 8500, loss 3.06183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [32:59<1:01:10, 282.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:33:13.690290: step 9000, loss 2.86906\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:33:25.888319: loss 0.0510954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.94      0.97      0.96     73225\n",
      "       AFW_B       0.72      0.36      0.48       449\n",
      "       AFW_I       0.70      0.31      0.43       175\n",
      "       ANM_B       0.78      0.53      0.63       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.75      0.70      0.72      5612\n",
      "       CVL_I       0.47      0.25      0.33       328\n",
      "       DAT_B       0.94      0.92      0.93      2587\n",
      "       DAT_I       0.90      0.89      0.89       863\n",
      "       EVT_B       0.81      0.77      0.79      1130\n",
      "       EVT_I       0.79      0.72      0.75       729\n",
      "       FLD_B       0.69      0.33      0.45       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.80      0.68      0.74      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.95      0.95      5569\n",
      "       NUM_I       0.77      0.77      0.77       833\n",
      "       ORG_B       0.81      0.81      0.81      4251\n",
      "       ORG_I       0.59      0.63      0.61       474\n",
      "       PER_B       0.84      0.80      0.82      4263\n",
      "       PER_I       0.65      0.74      0.69       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.92      0.86      0.89       341\n",
      "       TIM_I       0.93      0.88      0.90        91\n",
      "       TRM_B       0.71      0.63      0.67      1965\n",
      "       TRM_I       0.40      0.48      0.43       320\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    106858\n",
      "   macro avg       0.60      0.53      0.56    106858\n",
      "weighted avg       0.90      0.91      0.90    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9065395197364727, f1: 0.77400014107357\n",
      "2019-05-29T17:35:14.201457: step 9500, loss 3.19423\n",
      "2019-05-29T17:36:57.471357: step 10000, loss 3.12235\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:37:09.626172: loss 0.0501713\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.95      0.97      0.96     73225\n",
      "       AFW_B       0.71      0.38      0.49       449\n",
      "       AFW_I       0.60      0.34      0.43       175\n",
      "       ANM_B       0.78      0.54      0.64       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.72      0.74      0.73      5612\n",
      "       CVL_I       0.34      0.41      0.37       328\n",
      "       DAT_B       0.93      0.93      0.93      2587\n",
      "       DAT_I       0.91      0.87      0.89       863\n",
      "       EVT_B       0.81      0.78      0.79      1130\n",
      "       EVT_I       0.69      0.79      0.74       729\n",
      "       FLD_B       0.70      0.39      0.50       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.79      0.70      0.74      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.95      0.94      5569\n",
      "       NUM_I       0.78      0.75      0.77       833\n",
      "       ORG_B       0.83      0.80      0.81      4251\n",
      "       ORG_I       0.61      0.61      0.61       474\n",
      "       PER_B       0.83      0.82      0.82      4263\n",
      "       PER_I       0.67      0.72      0.69       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.88      0.88      0.88       341\n",
      "       TIM_I       0.90      0.91      0.91        91\n",
      "       TRM_B       0.79      0.58      0.67      1965\n",
      "       TRM_I       0.39      0.41      0.40       320\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    106858\n",
      "   macro avg       0.59      0.55      0.56    106858\n",
      "weighted avg       0.91      0.91      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9078871025098729, f1: 0.7777836033485381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [37:53<57:08, 285.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:38:55.722618: step 10500, loss 2.74715\n",
      "2019-05-29T17:40:39.126402: step 11000, loss 2.1566\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:40:51.212405: loss 0.0489084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.94      0.97      0.96     73225\n",
      "       AFW_B       0.76      0.35      0.48       449\n",
      "       AFW_I       0.63      0.37      0.46       175\n",
      "       ANM_B       0.76      0.58      0.66       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.80      0.68      0.73      5612\n",
      "       CVL_I       0.43      0.41      0.42       328\n",
      "       DAT_B       0.94      0.93      0.93      2587\n",
      "       DAT_I       0.89      0.90      0.89       863\n",
      "       EVT_B       0.84      0.76      0.80      1130\n",
      "       EVT_I       0.79      0.77      0.78       729\n",
      "       FLD_B       0.71      0.37      0.49       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.78      0.72      0.75      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.94      0.94      5569\n",
      "       NUM_I       0.79      0.75      0.77       833\n",
      "       ORG_B       0.83      0.80      0.81      4251\n",
      "       ORG_I       0.59      0.65      0.62       474\n",
      "       PER_B       0.85      0.81      0.83      4263\n",
      "       PER_I       0.65      0.76      0.70       540\n",
      "       PLT_B       0.50      0.06      0.11        17\n",
      "       TIM_B       0.91      0.88      0.89       341\n",
      "       TIM_I       0.88      0.93      0.90        91\n",
      "       TRM_B       0.76      0.62      0.68      1965\n",
      "       TRM_I       0.41      0.43      0.42       320\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    106858\n",
      "   macro avg       0.62      0.55      0.57    106858\n",
      "weighted avg       0.91      0.91      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9101049991577608, f1: 0.7821655142918241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [42:34<52:07, 284.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:42:40.502751: step 11500, loss 3.14295\n",
      "2019-05-29T17:44:24.585442: step 12000, loss 2.42044\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:44:36.809903: loss 0.0479025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.95      0.97      0.96     73225\n",
      "       AFW_B       0.70      0.36      0.47       449\n",
      "       AFW_I       0.56      0.39      0.46       175\n",
      "       ANM_B       0.76      0.59      0.66       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.80      0.69      0.74      5612\n",
      "       CVL_I       0.45      0.40      0.43       328\n",
      "       DAT_B       0.94      0.93      0.94      2587\n",
      "       DAT_I       0.89      0.90      0.90       863\n",
      "       EVT_B       0.82      0.78      0.80      1130\n",
      "       EVT_I       0.74      0.79      0.77       729\n",
      "       FLD_B       0.65      0.38      0.48       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.79      0.73      0.76      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.94      0.95      0.94      5569\n",
      "       NUM_I       0.73      0.80      0.77       833\n",
      "       ORG_B       0.81      0.82      0.81      4251\n",
      "       ORG_I       0.60      0.64      0.62       474\n",
      "       PER_B       0.87      0.81      0.83      4263\n",
      "       PER_I       0.66      0.77      0.71       540\n",
      "       PLT_B       0.00      0.00      0.00        17\n",
      "       TIM_B       0.92      0.89      0.90       341\n",
      "       TIM_I       0.90      0.90      0.90        91\n",
      "       TRM_B       0.71      0.66      0.68      1965\n",
      "       TRM_I       0.34      0.53      0.42       320\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    106858\n",
      "   macro avg       0.59      0.56      0.57    106858\n",
      "weighted avg       0.91      0.91      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9108068651855734, f1: 0.7834195793080306\n",
      "2019-05-29T17:46:25.204612: step 12500, loss 3.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [47:16<47:16, 283.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:48:10.482881: step 13000, loss 2.70374\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:48:22.964845: loss 0.0471624\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.95      0.97      0.96     73225\n",
      "       AFW_B       0.69      0.41      0.52       449\n",
      "       AFW_I       0.58      0.41      0.48       175\n",
      "       ANM_B       0.76      0.59      0.66       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.80      0.71      0.75      5612\n",
      "       CVL_I       0.38      0.45      0.41       328\n",
      "       DAT_B       0.95      0.92      0.93      2587\n",
      "       DAT_I       0.90      0.87      0.89       863\n",
      "       EVT_B       0.84      0.79      0.81      1130\n",
      "       EVT_I       0.81      0.75      0.78       729\n",
      "       FLD_B       0.65      0.47      0.55       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.81      0.73      0.77      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.79      0.76      0.77       833\n",
      "       ORG_B       0.85      0.81      0.83      4251\n",
      "       ORG_I       0.65      0.63      0.64       474\n",
      "       PER_B       0.84      0.83      0.83      4263\n",
      "       PER_I       0.64      0.79      0.71       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.90      0.89      0.90       341\n",
      "       TIM_I       0.93      0.90      0.92        91\n",
      "       TRM_B       0.74      0.64      0.69      1965\n",
      "       TRM_I       0.40      0.50      0.44       320\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    106858\n",
      "   macro avg       0.62      0.57      0.59    106858\n",
      "weighted avg       0.91      0.91      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.913511388946078, f1: 0.7910202784984381\n",
      "2019-05-29T17:50:11.497525: step 13500, loss 2.31345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [51:57<42:25, 282.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:51:57.169320: step 14000, loss 2.33772\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:52:09.337493: loss 0.0463765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.66      0.42      0.51       449\n",
      "       AFW_I       0.51      0.41      0.45       175\n",
      "       ANM_B       0.79      0.57      0.66       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.78      0.74      0.76      5612\n",
      "       CVL_I       0.41      0.42      0.42       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.89      0.91      0.90       863\n",
      "       EVT_B       0.82      0.80      0.81      1130\n",
      "       EVT_I       0.75      0.80      0.78       729\n",
      "       FLD_B       0.65      0.48      0.55       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.79      0.75      0.77      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.77      0.80      0.78       833\n",
      "       ORG_B       0.83      0.83      0.83      4251\n",
      "       ORG_I       0.63      0.66      0.64       474\n",
      "       PER_B       0.84      0.84      0.84      4263\n",
      "       PER_I       0.67      0.79      0.72       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.90      0.89      0.90       341\n",
      "       TIM_I       0.88      0.92      0.90        91\n",
      "       TRM_B       0.75      0.65      0.70      1965\n",
      "       TRM_I       0.44      0.46      0.45       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.62      0.57      0.59    106858\n",
      "weighted avg       0.91      0.92      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.915186509199124, f1: 0.7950825381347079\n",
      "2019-05-29T17:53:57.965496: step 14500, loss 3.62191\n",
      "2019-05-29T17:55:42.871079: step 15000, loss 1.98162\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:55:54.793154: loss 0.046124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.95      0.97      0.96     73225\n",
      "       AFW_B       0.67      0.42      0.51       449\n",
      "       AFW_I       0.51      0.41      0.45       175\n",
      "       ANM_B       0.77      0.58      0.66       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.81      0.71      0.76      5612\n",
      "       CVL_I       0.48      0.42      0.45       328\n",
      "       DAT_B       0.95      0.92      0.94      2587\n",
      "       DAT_I       0.90      0.89      0.90       863\n",
      "       EVT_B       0.83      0.78      0.80      1130\n",
      "       EVT_I       0.76      0.81      0.78       729\n",
      "       FLD_B       0.70      0.42      0.52       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.80      0.75      0.78      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.96      0.94      0.95      5569\n",
      "       NUM_I       0.78      0.79      0.78       833\n",
      "       ORG_B       0.87      0.80      0.83      4251\n",
      "       ORG_I       0.65      0.67      0.66       474\n",
      "       PER_B       0.85      0.83      0.84      4263\n",
      "       PER_I       0.67      0.79      0.72       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.86      0.88      0.87       341\n",
      "       TIM_I       0.86      0.92      0.89        91\n",
      "       TRM_B       0.78      0.62      0.69      1965\n",
      "       TRM_I       0.43      0.51      0.47       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.62      0.57      0.59    106858\n",
      "weighted avg       0.91      0.92      0.91    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9153923899006158, f1: 0.7949091684738171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [56:52<38:12, 286.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T17:57:41.380018: step 15500, loss 2.22132\n",
      "2019-05-29T17:59:28.996390: step 16000, loss 1.95848\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T17:59:41.032216: loss 0.0455394\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.68      0.41      0.51       449\n",
      "       AFW_I       0.55      0.40      0.46       175\n",
      "       ANM_B       0.77      0.60      0.67       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.81      0.73      0.77      5612\n",
      "       CVL_I       0.49      0.42      0.45       328\n",
      "       DAT_B       0.93      0.94      0.94      2587\n",
      "       DAT_I       0.88      0.91      0.90       863\n",
      "       EVT_B       0.83      0.80      0.82      1130\n",
      "       EVT_I       0.80      0.76      0.78       729\n",
      "       FLD_B       0.64      0.49      0.55       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.77      0.79      0.78      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.73      0.83      0.78       833\n",
      "       ORG_B       0.86      0.81      0.84      4251\n",
      "       ORG_I       0.68      0.64      0.66       474\n",
      "       PER_B       0.83      0.85      0.84      4263\n",
      "       PER_I       0.66      0.81      0.73       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.88      0.92      0.90       341\n",
      "       TIM_I       0.89      0.92      0.91        91\n",
      "       TRM_B       0.72      0.69      0.71      1965\n",
      "       TRM_I       0.41      0.49      0.45       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.62      0.58      0.59    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9172733908551536, f1: 0.7988023535146049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [1:01:34<33:16, 285.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:01:26.878476: step 16500, loss 1.49608\n",
      "2019-05-29T18:03:11.784041: step 17000, loss 2.23023\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:03:23.799107: loss 0.0454245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.64      0.43      0.52       449\n",
      "       AFW_I       0.48      0.45      0.46       175\n",
      "       ANM_B       0.76      0.64      0.69       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.78      0.77      0.77      5612\n",
      "       CVL_I       0.43      0.41      0.42       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.90      0.89      0.90       863\n",
      "       EVT_B       0.83      0.78      0.80      1130\n",
      "       EVT_I       0.75      0.80      0.77       729\n",
      "       FLD_B       0.65      0.51      0.57       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.81      0.76      0.78      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.79      0.79      0.79       833\n",
      "       ORG_B       0.84      0.83      0.84      4251\n",
      "       ORG_I       0.58      0.74      0.65       474\n",
      "       PER_B       0.84      0.85      0.85      4263\n",
      "       PER_I       0.70      0.80      0.74       540\n",
      "       PLT_B       0.75      0.18      0.29        17\n",
      "       TIM_B       0.89      0.91      0.90       341\n",
      "       TIM_I       0.89      0.95      0.91        91\n",
      "       TRM_B       0.73      0.69      0.71      1965\n",
      "       TRM_I       0.41      0.60      0.49       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.62      0.59      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9174886297703494, f1: 0.8018680273285479\n",
      "2019-05-29T18:05:11.188920: step 17500, loss 2.28395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [1:06:17<28:26, 284.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:06:59.914945: step 18000, loss 1.98722\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:07:12.127181: loss 0.0456552\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.95      0.97      0.96     73225\n",
      "       AFW_B       0.73      0.41      0.52       449\n",
      "       AFW_I       0.68      0.39      0.50       175\n",
      "       ANM_B       0.76      0.61      0.68       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.80      0.75      0.78      5612\n",
      "       CVL_I       0.45      0.46      0.46       328\n",
      "       DAT_B       0.94      0.93      0.94      2587\n",
      "       DAT_I       0.90      0.90      0.90       863\n",
      "       EVT_B       0.84      0.78      0.81      1130\n",
      "       EVT_I       0.81      0.76      0.78       729\n",
      "       FLD_B       0.67      0.43      0.53       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.82      0.77      0.79      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.76      0.79      0.78       833\n",
      "       ORG_B       0.86      0.82      0.84      4251\n",
      "       ORG_I       0.66      0.65      0.65       474\n",
      "       PER_B       0.88      0.83      0.85      4263\n",
      "       PER_I       0.72      0.77      0.75       540\n",
      "       PLT_B       0.75      0.18      0.29        17\n",
      "       TIM_B       0.90      0.89      0.90       341\n",
      "       TIM_I       0.89      0.95      0.91        91\n",
      "       TRM_B       0.71      0.69      0.70      1965\n",
      "       TRM_I       0.43      0.47      0.45       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.64      0.58      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9190514514589455, f1: 0.8052271531310297\n",
      "2019-05-29T18:08:58.587271: step 18500, loss 2.52565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [1:10:59<23:38, 283.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:10:45.699925: step 19000, loss 1.79957\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:10:57.679203: loss 0.0446826\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.71      0.45      0.55       449\n",
      "       AFW_I       0.68      0.43      0.52       175\n",
      "       ANM_B       0.79      0.61      0.69       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.78      0.78      0.78      5612\n",
      "       CVL_I       0.42      0.36      0.39       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.89      0.89      0.89       863\n",
      "       EVT_B       0.81      0.80      0.81      1130\n",
      "       EVT_I       0.74      0.80      0.77       729\n",
      "       FLD_B       0.74      0.40      0.52       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.83      0.78      0.80      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.81      0.76      0.78       833\n",
      "       ORG_B       0.86      0.83      0.84      4251\n",
      "       ORG_I       0.63      0.69      0.66       474\n",
      "       PER_B       0.85      0.86      0.85      4263\n",
      "       PER_I       0.72      0.78      0.75       540\n",
      "       PLT_B       0.75      0.18      0.29        17\n",
      "       TIM_B       0.90      0.89      0.90       341\n",
      "       TIM_I       0.89      0.91      0.90        91\n",
      "       TRM_B       0.77      0.67      0.72      1965\n",
      "       TRM_I       0.48      0.48      0.48       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.64      0.58      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.920249302813079, f1: 0.8075669302261064\n",
      "2019-05-29T18:12:41.732747: step 19500, loss 1.74509\n",
      "2019-05-29T18:14:27.994861: step 20000, loss 1.97759\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:14:40.191595: loss 0.0443182\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.67      0.45      0.54       449\n",
      "       AFW_I       0.64      0.48      0.55       175\n",
      "       ANM_B       0.75      0.66      0.70       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.79      0.77      0.78      5612\n",
      "       CVL_I       0.43      0.42      0.43       328\n",
      "       DAT_B       0.95      0.94      0.94      2587\n",
      "       DAT_I       0.91      0.90      0.91       863\n",
      "       EVT_B       0.85      0.78      0.81      1130\n",
      "       EVT_I       0.79      0.78      0.79       729\n",
      "       FLD_B       0.66      0.48      0.56       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.82      0.78      0.80      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.77      0.81      0.79       833\n",
      "       ORG_B       0.83      0.85      0.84      4251\n",
      "       ORG_I       0.66      0.62      0.64       474\n",
      "       PER_B       0.86      0.85      0.86      4263\n",
      "       PER_I       0.73      0.80      0.76       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.88      0.90      0.89       341\n",
      "       TIM_I       0.89      0.93      0.91        91\n",
      "       TRM_B       0.74      0.69      0.71      1965\n",
      "       TRM_I       0.49      0.46      0.47       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.63      0.59      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9206423477886541, f1: 0.8089763125086576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [1:15:54<19:08, 287.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:16:30.016677: step 20500, loss 2.44378\n",
      "2019-05-29T18:18:16.681374: step 21000, loss 2.22316\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:18:28.679317: loss 0.0444024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.67      0.43      0.53       449\n",
      "       AFW_I       0.57      0.45      0.50       175\n",
      "       ANM_B       0.77      0.66      0.71       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.81      0.75      0.78      5612\n",
      "       CVL_I       0.41      0.49      0.45       328\n",
      "       DAT_B       0.95      0.93      0.94      2587\n",
      "       DAT_I       0.90      0.91      0.90       863\n",
      "       EVT_B       0.80      0.82      0.81      1130\n",
      "       EVT_I       0.77      0.80      0.79       729\n",
      "       FLD_B       0.68      0.44      0.54       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.81      0.78      0.79      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.76      0.80      0.78       833\n",
      "       ORG_B       0.86      0.83      0.85      4251\n",
      "       ORG_I       0.68      0.65      0.66       474\n",
      "       PER_B       0.88      0.84      0.86      4263\n",
      "       PER_I       0.73      0.76      0.74       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.88      0.91      0.89       341\n",
      "       TIM_I       0.88      0.92      0.90        91\n",
      "       TRM_B       0.73      0.69      0.71      1965\n",
      "       TRM_I       0.43      0.48      0.45       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.63      0.58      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9204926163693874, f1: 0.8081404489475064\n",
      "2019-05-29T18:20:14.270070: step 21500, loss 2.00444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [1:20:35<14:15, 285.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:21:59.388814: step 22000, loss 2.2217\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:22:11.398646: loss 0.0441342\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.64      0.45      0.52       449\n",
      "       AFW_I       0.57      0.45      0.50       175\n",
      "       ANM_B       0.74      0.67      0.70       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.81      0.76      0.78      5612\n",
      "       CVL_I       0.42      0.52      0.47       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.90      0.92      0.91       863\n",
      "       EVT_B       0.84      0.81      0.82      1130\n",
      "       EVT_I       0.79      0.83      0.81       729\n",
      "       FLD_B       0.68      0.50      0.58       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.80      0.79      0.80      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.96      0.94      0.95      5569\n",
      "       NUM_I       0.76      0.82      0.79       833\n",
      "       ORG_B       0.88      0.82      0.85      4251\n",
      "       ORG_I       0.66      0.69      0.67       474\n",
      "       PER_B       0.86      0.85      0.86      4263\n",
      "       PER_I       0.70      0.81      0.75       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.90      0.91      0.91       341\n",
      "       TIM_I       0.89      0.93      0.91        91\n",
      "       TRM_B       0.72      0.69      0.71      1965\n",
      "       TRM_I       0.38      0.57      0.46       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.62      0.60      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9211851241834959, f1: 0.8102925281545275\n",
      "2019-05-29T18:23:57.835848: step 22500, loss 2.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [1:25:16<09:27, 283.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:25:44.491797: step 23000, loss 1.71218\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:25:56.635887: loss 0.045134\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.71      0.45      0.55       449\n",
      "       AFW_I       0.73      0.37      0.49       175\n",
      "       ANM_B       0.77      0.65      0.70       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.81      0.77      0.79      5612\n",
      "       CVL_I       0.49      0.44      0.46       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.92      0.90      0.91       863\n",
      "       EVT_B       0.83      0.80      0.82      1130\n",
      "       EVT_I       0.81      0.82      0.81       729\n",
      "       FLD_B       0.65      0.48      0.55       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.77      0.82      0.79      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.96      0.94      0.95      5569\n",
      "       NUM_I       0.80      0.77      0.78       833\n",
      "       ORG_B       0.87      0.82      0.84      4251\n",
      "       ORG_I       0.65      0.68      0.66       474\n",
      "       PER_B       0.84      0.86      0.85      4263\n",
      "       PER_I       0.68      0.82      0.75       540\n",
      "       PLT_B       0.67      0.12      0.20        17\n",
      "       TIM_B       0.88      0.91      0.90       341\n",
      "       TIM_I       0.89      0.91      0.90        91\n",
      "       TRM_B       0.72      0.68      0.70      1965\n",
      "       TRM_I       0.39      0.57      0.46       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.63      0.59      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.9211757659697917, f1: 0.8110916743162964\n",
      "2019-05-29T18:27:43.204033: step 23500, loss 2.22932\n",
      "2019-05-29T18:29:31.606114: step 24000, loss 1.81283\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:29:43.725427: loss 0.0440634\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.69      0.45      0.54       449\n",
      "       AFW_I       0.52      0.48      0.50       175\n",
      "       ANM_B       0.77      0.65      0.70       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.79      0.79      0.79      5612\n",
      "       CVL_I       0.42      0.47      0.45       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.91      0.90      0.91       863\n",
      "       EVT_B       0.83      0.82      0.82      1130\n",
      "       EVT_I       0.75      0.83      0.79       729\n",
      "       FLD_B       0.65      0.49      0.56       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.83      0.78      0.80      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.95      0.95      0.95      5569\n",
      "       NUM_I       0.76      0.81      0.78       833\n",
      "       ORG_B       0.87      0.83      0.85      4251\n",
      "       ORG_I       0.68      0.66      0.67       474\n",
      "       PER_B       0.86      0.86      0.86      4263\n",
      "       PER_I       0.73      0.78      0.75       540\n",
      "       PLT_B       0.60      0.18      0.27        17\n",
      "       TIM_B       0.89      0.92      0.90       341\n",
      "       TIM_I       0.89      0.92      0.91        91\n",
      "       TRM_B       0.75      0.69      0.72      1965\n",
      "       TRM_I       0.48      0.51      0.49       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.63      0.60      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.922195811263546, f1: 0.8153694171476109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [1:30:11<04:47, 287.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29T18:31:27.561461: step 24500, loss 1.49157\n",
      "2019-05-29T18:33:15.523294: step 25000, loss 1.9681\n",
      "\n",
      "Dev Evaluation\n",
      "2019-05-29T18:33:27.599129: loss 0.0448306\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.96      0.97      0.96     73225\n",
      "       AFW_B       0.71      0.45      0.55       449\n",
      "       AFW_I       0.62      0.43      0.51       175\n",
      "       ANM_B       0.76      0.66      0.71       644\n",
      "       ANM_I       0.00      0.00      0.00         5\n",
      "       CVL_B       0.80      0.78      0.79      5612\n",
      "       CVL_I       0.41      0.53      0.46       328\n",
      "       DAT_B       0.94      0.94      0.94      2587\n",
      "       DAT_I       0.90      0.91      0.91       863\n",
      "       EVT_B       0.83      0.81      0.82      1130\n",
      "       EVT_I       0.76      0.82      0.79       729\n",
      "       FLD_B       0.68      0.46      0.55       225\n",
      "       FLD_I       0.00      0.00      0.00         8\n",
      "       LOC_B       0.84      0.77      0.80      2165\n",
      "       LOC_I       0.00      0.00      0.00        25\n",
      "       MAT_B       0.00      0.00      0.00        21\n",
      "       MAT_I       0.00      0.00      0.00         3\n",
      "       NUM_B       0.96      0.94      0.95      5569\n",
      "       NUM_I       0.79      0.79      0.79       833\n",
      "       ORG_B       0.87      0.83      0.85      4251\n",
      "       ORG_I       0.67      0.65      0.66       474\n",
      "       PER_B       0.86      0.86      0.86      4263\n",
      "       PER_I       0.72      0.76      0.74       540\n",
      "       PLT_B       0.50      0.12      0.19        17\n",
      "       TIM_B       0.90      0.92      0.91       341\n",
      "       TIM_I       0.91      0.92      0.92        91\n",
      "       TRM_B       0.72      0.70      0.71      1965\n",
      "       TRM_I       0.42      0.54      0.47       320\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    106858\n",
      "   macro avg       0.63      0.59      0.60    106858\n",
      "weighted avg       0.92      0.92      0.92    106858\n",
      "\n",
      "Chunk based evaluation: acc: 0.921802766287971, f1: 0.8130420425117749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [1:34:51<00:00, 285.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    model = Model(\n",
    "        num_classes=len(tag_list),\n",
    "        vocab_size=len(word_list),\n",
    "        char_size=len(char_list),\n",
    "        word_embedding_dim=Config.word_embedding_dim,\n",
    "        char_embedding_dim=Config.char_embedding_dim,\n",
    "        hidden_size_word=Config.hidden_size_word,\n",
    "        hidden_size_char=Config.hidden_size_char\n",
    "    )\n",
    "    \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # train_op = tf.train.AdamOptimizer(Config.learning_rate).minimize(model.loss, global_step=global_step)\n",
    "    \n",
    "    optimizer = tf.train.AdadeltaOptimizer(Config.learning_rate, Config.decay_rate, 1e-6)\n",
    "    gvs = optimizer.compute_gradients(model.loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in gvs]\n",
    "    train_op = optimizer.apply_gradients(capped_gvs, global_step=global_step)\n",
    "    \n",
    "    # Output directory for models and summary\n",
    "    timestamp = str(int(time.time()))\n",
    "    out_dir = os.path.abspath(os.path.join(os.path.curdir, \"34.runs\", timestamp))\n",
    "    print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     pretrain_W = load_glove(Config.word_embedding_dim, word2idx)\n",
    "#     sess.run(model._word_embeddings.assign(pretrain_W))\n",
    "#     print(\"Success to load pre-trained glove model!\\n\")\n",
    "    \n",
    "    # Generate batches\n",
    "    batches = batch_iter(train_df, Config.batch_size, Config.num_epochs)\n",
    "    for batch_df in batches:\n",
    "        word_ids, labels, sequence_lengths, char_ids, word_lengths = get_feed_dict(batch_df)\n",
    "        feed_dict = {\n",
    "            model.word_ids: word_ids,\n",
    "            model.labels: labels,\n",
    "            model.sequence_lengths: sequence_lengths,\n",
    "            model.char_ids: char_ids,\n",
    "            model.word_lengths: word_lengths,\n",
    "            model.dropout: 0.75,\n",
    "        }\n",
    "        _, step, loss, logits, trans_params = sess.run([\n",
    "            train_op, global_step, model.loss, model.logits, model.trans_params], feed_dict)\n",
    "        \n",
    "        predictions = model.viterbi_decode(logits, trans_params)\n",
    "        \n",
    "        # Training log display\n",
    "        if step % Config.display_every == 0:\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}\".format(time_str, step, loss))\n",
    "            \n",
    "        # Evaluation\n",
    "        if step % Config.evaluate_every == 0:\n",
    "            batches = batch_iter(dev_df, Config.batch_size, 1, tqdm_disable=True)\n",
    "            \n",
    "            total_loss, predictions_all, labels_all, sequence_lengths_all  = 0, [], [], []\n",
    "            for batch_df in batches:\n",
    "                word_ids, labels, sequence_lengths, char_ids, word_lengths = get_feed_dict(batch_df)\n",
    "                feed_dict = {\n",
    "                    model.word_ids: word_ids,\n",
    "                    model.labels: labels,\n",
    "                    model.sequence_lengths: sequence_lengths,\n",
    "                    model.char_ids: char_ids,\n",
    "                    model.word_lengths: word_lengths,\n",
    "                    model.dropout: 1.0,\n",
    "                }\n",
    "                loss, logits, trans_params = sess.run([model.loss, model.logits, model.trans_params], feed_dict)\n",
    "                predictions = model.viterbi_decode(logits, trans_params)\n",
    "                \n",
    "                total_loss += loss\n",
    "                predictions_all += predictions.tolist()\n",
    "                labels_all += labels.tolist()\n",
    "                sequence_lengths_all += sequence_lengths.tolist()\n",
    "        \n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"\\nDev Evaluation\\n{}: loss {:g}\\n\".format(time_str, total_loss/len(predictions_all)))\n",
    "            evaluation(labels_all, predictions_all, sequence_lengths_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
