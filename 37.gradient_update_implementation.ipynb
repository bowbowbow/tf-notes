{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://github.com/WegraLee/deep-learning-from-scratch\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "class Dataset:\n",
    "    url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    dataset_dir = './data'\n",
    "    save_file = dataset_dir + \"/mnist.pkl\"\n",
    "    url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    key_file = {\n",
    "        'train_img':'train-images-idx3-ubyte.gz',\n",
    "        'train_label':'train-labels-idx1-ubyte.gz',\n",
    "        'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "        'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    img_dim = (1, 28, 28)\n",
    "    img_size = 784\n",
    "    \n",
    "    def _download(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "        if os.path.exists(file_path):\n",
    "            return\n",
    "\n",
    "        print(\"Downloading \" + file_name + \" ... \")\n",
    "        urllib.request.urlretrieve(self.url_base + file_name, file_path)\n",
    "        print(\"Done\")\n",
    "    \n",
    "    def download_mnist(self):\n",
    "        for v in self.key_file.values():\n",
    "            self._download(v)\n",
    "            \n",
    "    def _load_label(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "\n",
    "        print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "                labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        print(\"Done\")\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def _load_img(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "\n",
    "        print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, self.img_size)\n",
    "        print(\"Done\")\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def _convert_numpy(self):\n",
    "        dataset = {}\n",
    "        dataset['train_img'] =  self._load_img(self.key_file['train_img'])\n",
    "        dataset['train_label'] = self._load_label(self.key_file['train_label'])    \n",
    "        dataset['test_img'] = self._load_img(self.key_file['test_img'])\n",
    "        dataset['test_label'] = self._load_label(self.key_file['test_label'])\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    def _change_one_hot_label(self, X):\n",
    "        T = np.zeros((X.size, 10))\n",
    "        for idx, row in enumerate(T):\n",
    "            row[X[idx]] = 1\n",
    "\n",
    "        return T\n",
    "\n",
    "    def init_mnist(self):\n",
    "        self.download_mnist()\n",
    "        dataset = self._convert_numpy()\n",
    "        print(\"Creating pickle file ...\")\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(dataset, f, -1)\n",
    "        print(\"Done!\")\n",
    "        \n",
    "\n",
    "    def load_mnist(self, normalize=True, flatten=True, one_hot_label=False):\n",
    "        \"\"\"MNIST 데이터셋 읽기\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
    "        one_hot_label : \n",
    "            one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
    "            one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
    "        flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.save_file):\n",
    "            self.init_mnist()\n",
    "\n",
    "        with open(self.save_file, 'rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "\n",
    "        if normalize:\n",
    "            for key in ('train_img', 'test_img'):\n",
    "                dataset[key] = dataset[key].astype(np.float32)\n",
    "                dataset[key] /= 255.0\n",
    "\n",
    "        if one_hot_label:\n",
    "            dataset['train_label'] = self._change_one_hot_label(dataset['train_label'])\n",
    "            dataset['test_label'] = self._change_one_hot_label(dataset['test_label'])    \n",
    "\n",
    "        if not flatten:\n",
    "             for key in ('train_img', 'test_img'):\n",
    "                dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "        return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
    "\n",
    "dataset = Dataset()\n",
    "(x_train, t_train), (x_test, t_test) = dataset.load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/10000 [00:00<52:40,  3.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.09035, 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 659/10000 [00:02<01:31, 102.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.7873333333333333, 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1260/10000 [00:03<00:31, 275.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.8755666666666667, 0.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1906/10000 [00:05<00:28, 281.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.8952833333333333, 0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2498/10000 [00:06<00:26, 284.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9066333333333333, 0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3100/10000 [00:08<00:24, 284.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.91345, 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3696/10000 [00:09<00:22, 281.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9189166666666667, 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4293/10000 [00:11<00:20, 284.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9237333333333333, 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4886/10000 [00:12<00:18, 281.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.928, 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5483/10000 [00:14<00:15, 283.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9311333333333334, 0.9317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6081/10000 [00:15<00:13, 280.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9340666666666667, 0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6683/10000 [00:17<00:11, 284.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9364166666666667, 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7279/10000 [00:19<00:09, 283.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9389166666666666, 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 7867/10000 [00:20<00:07, 280.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9409666666666666, 0.9408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8468/10000 [00:22<00:05, 283.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.94235, 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9068/10000 [00:23<00:03, 284.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9445666666666667, 0.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9670/10000 [00:25<00:01, 284.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9457333333333333, 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 387.79it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in tqdm(range(iters_num)):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance\n",
    "\n",
    "numerical gradient: 22.01it/s\n",
    "\n",
    "back propagation: 387.79it/s\n",
    "\n",
    "\n",
    "back propagation is 17 times faster than numerical gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
