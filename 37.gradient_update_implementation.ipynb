{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://github.com/WegraLee/deep-learning-from-scratch\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "class Dataset:\n",
    "    url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    dataset_dir = './data/mnist'\n",
    "    save_file = dataset_dir + \"/mnist.pkl\"\n",
    "    url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    key_file = {\n",
    "        'train_img':'train-images-idx3-ubyte.gz',\n",
    "        'train_label':'train-labels-idx1-ubyte.gz',\n",
    "        'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "        'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    img_dim = (1, 28, 28)\n",
    "    img_size = 784\n",
    "    \n",
    "    def _download(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "        if os.path.exists(file_path):\n",
    "            return\n",
    "\n",
    "        print(\"Downloading \" + file_name + \" ... \")\n",
    "        urllib.request.urlretrieve(self.url_base + file_name, file_path)\n",
    "        print(\"Done\")\n",
    "    \n",
    "    def download_mnist(self):\n",
    "        for v in self.key_file.values():\n",
    "            self._download(v)\n",
    "            \n",
    "    def _load_label(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "\n",
    "        print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "                labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        print(\"Done\")\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def _load_img(self, file_name):\n",
    "        file_path = self.dataset_dir + \"/\" + file_name\n",
    "\n",
    "        print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "                data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, self.img_size)\n",
    "        print(\"Done\")\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def _convert_numpy(self):\n",
    "        dataset = {}\n",
    "        dataset['train_img'] =  self._load_img(self.key_file['train_img'])\n",
    "        dataset['train_label'] = self._load_label(self.key_file['train_label'])    \n",
    "        dataset['test_img'] = self._load_img(self.key_file['test_img'])\n",
    "        dataset['test_label'] = self._load_label(self.key_file['test_label'])\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    def _change_one_hot_label(self, X):\n",
    "        T = np.zeros((X.size, 10))\n",
    "        for idx, row in enumerate(T):\n",
    "            row[X[idx]] = 1\n",
    "\n",
    "        return T\n",
    "\n",
    "    def init_mnist(self):\n",
    "        self.download_mnist()\n",
    "        dataset = self._convert_numpy()\n",
    "        print(\"Creating pickle file ...\")\n",
    "        with open(self.save_file, 'wb') as f:\n",
    "            pickle.dump(dataset, f, -1)\n",
    "        print(\"Done!\")\n",
    "        \n",
    "\n",
    "    def load_mnist(self, normalize=True, flatten=True, one_hot_label=False):\n",
    "        \"\"\"MNIST 데이터셋 읽기\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
    "        one_hot_label : \n",
    "            one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
    "            one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
    "        flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.save_file):\n",
    "            self.init_mnist()\n",
    "\n",
    "        with open(self.save_file, 'rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "\n",
    "        if normalize:\n",
    "            for key in ('train_img', 'test_img'):\n",
    "                dataset[key] = dataset[key].astype(np.float32)\n",
    "                dataset[key] /= 255.0\n",
    "\n",
    "        if one_hot_label:\n",
    "            dataset['train_label'] = self._change_one_hot_label(dataset['train_label'])\n",
    "            dataset['test_label'] = self._change_one_hot_label(dataset['test_label'])    \n",
    "\n",
    "        if not flatten:\n",
    "             for key in ('train_img', 'test_img'):\n",
    "                dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "        return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
    "\n",
    "dataset = Dataset()\n",
    "(x_train, t_train), (x_test, t_test) = dataset.load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 53/10000 [00:00<51:04,  3.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.11236666666666667, 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 709/10000 [00:02<01:11, 129.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.7782666666666667, 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1256/10000 [00:03<00:31, 277.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.8775333333333334, 0.8827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1862/10000 [00:05<00:28, 288.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.89915, 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2461/10000 [00:06<00:26, 280.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9087333333333333, 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3066/10000 [00:08<00:24, 284.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9146166666666666, 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3669/10000 [00:09<00:22, 284.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9200666666666667, 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4271/10000 [00:11<00:20, 284.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9237833333333333, 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 4873/10000 [00:12<00:17, 287.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9276333333333333, 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5463/10000 [00:14<00:16, 279.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9300833333333334, 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6106/10000 [00:15<00:13, 283.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9333833333333333, 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6699/10000 [00:17<00:11, 283.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.93595, 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7298/10000 [00:19<00:09, 284.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9372166666666667, 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7898/10000 [00:20<00:07, 282.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9404333333333333, 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8489/10000 [00:22<00:05, 283.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9417666666666666, 0.9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9090/10000 [00:23<00:03, 284.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.9440166666666666, 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9691/10000 [00:25<00:01, 284.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.94605, 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 389.02it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in tqdm(range(iters_num)):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance\n",
    "\n",
    "numerical gradient: 22.01it/s\n",
    "\n",
    "back propagation: 387.79it/s\n",
    "\n",
    "\n",
    "back propagation is 17 times faster than numerical gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
