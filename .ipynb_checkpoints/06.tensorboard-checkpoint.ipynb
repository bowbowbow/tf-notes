{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://github.com/golbin/TensorFlow-Tutorials\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [털, 날개]\n",
    "x_data = np.array([[0,0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]])\n",
    "y_data = np.array([\n",
    "    [1, 0, 0], # 기타\n",
    "    [0, 1, 0], # 포유류\n",
    "    [0, 0, 1], # 조류\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.name_scope\n",
    "\n",
    "tf.name_scope로 묶은 블럭은 텐서보드에서 한 레이어 안에서 표현됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 10], -1.0, 1.0), name='W1')\n",
    "    b1 = tf.Variable(tf.zeros([10]), name='b1')\n",
    "    L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_uniform([10, 20], -1.0, 1.0), name='W2')\n",
    "    b2 = tf.Variable(tf.zeros([20]), name='b2')\n",
    "    L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_uniform([20, 3], -1.0, 1.0), name='W3')\n",
    "    b3 = tf.Variable(tf.zeros([3]), name='b3')\n",
    "    model = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    \n",
    "    # tf.summary.scalar를 이용해서 수집하고 싶은 값을 지정할 수 있음\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model/6')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서 정보 수집\n",
    "\n",
    "tensorboard --logdir=./logs 으로 실행하여 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Merge_4/MergeSummary:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "# 그래프와 텐서값들을 저장할 디렉토리 설정\n",
    "writer = tf.summary.FileWriter('./logs/6', sess.graph)\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 1 \n",
      "Cost : 0.738 \n",
      "Step : 2 \n",
      "Cost : 0.591 \n",
      "Step : 3 \n",
      "Cost : 0.470 \n",
      "Step : 4 \n",
      "Cost : 0.369 \n",
      "Step : 5 \n",
      "Cost : 0.286 \n",
      "Step : 6 \n",
      "Cost : 0.218 \n",
      "Step : 7 \n",
      "Cost : 0.164 \n",
      "Step : 8 \n",
      "Cost : 0.123 \n",
      "Step : 9 \n",
      "Cost : 0.091 \n",
      "Step : 10 \n",
      "Cost : 0.068 \n",
      "Step : 11 \n",
      "Cost : 0.051 \n",
      "Step : 12 \n",
      "Cost : 0.038 \n",
      "Step : 13 \n",
      "Cost : 0.029 \n",
      "Step : 14 \n",
      "Cost : 0.022 \n",
      "Step : 15 \n",
      "Cost : 0.017 \n",
      "Step : 16 \n",
      "Cost : 0.014 \n",
      "Step : 17 \n",
      "Cost : 0.011 \n",
      "Step : 18 \n",
      "Cost : 0.009 \n",
      "Step : 19 \n",
      "Cost : 0.007 \n",
      "Step : 20 \n",
      "Cost : 0.006 \n",
      "Step : 21 \n",
      "Cost : 0.005 \n",
      "Step : 22 \n",
      "Cost : 0.005 \n",
      "Step : 23 \n",
      "Cost : 0.004 \n",
      "Step : 24 \n",
      "Cost : 0.004 \n",
      "Step : 25 \n",
      "Cost : 0.003 \n",
      "Step : 26 \n",
      "Cost : 0.003 \n",
      "Step : 27 \n",
      "Cost : 0.003 \n",
      "Step : 28 \n",
      "Cost : 0.002 \n",
      "Step : 29 \n",
      "Cost : 0.002 \n",
      "Step : 30 \n",
      "Cost : 0.002 \n",
      "Step : 31 \n",
      "Cost : 0.002 \n",
      "Step : 32 \n",
      "Cost : 0.002 \n",
      "Step : 33 \n",
      "Cost : 0.001 \n",
      "Step : 34 \n",
      "Cost : 0.001 \n",
      "Step : 35 \n",
      "Cost : 0.001 \n",
      "Step : 36 \n",
      "Cost : 0.001 \n",
      "Step : 37 \n",
      "Cost : 0.001 \n",
      "Step : 38 \n",
      "Cost : 0.001 \n",
      "Step : 39 \n",
      "Cost : 0.001 \n",
      "Step : 40 \n",
      "Cost : 0.001 \n",
      "Step : 41 \n",
      "Cost : 0.001 \n",
      "Step : 42 \n",
      "Cost : 0.001 \n",
      "Step : 43 \n",
      "Cost : 0.001 \n",
      "Step : 44 \n",
      "Cost : 0.001 \n",
      "Step : 45 \n",
      "Cost : 0.001 \n",
      "Step : 46 \n",
      "Cost : 0.001 \n",
      "Step : 47 \n",
      "Cost : 0.001 \n",
      "Step : 48 \n",
      "Cost : 0.001 \n",
      "Step : 49 \n",
      "Cost : 0.001 \n",
      "Step : 50 \n",
      "Cost : 0.001 \n",
      "Step : 51 \n",
      "Cost : 0.001 \n",
      "Step : 52 \n",
      "Cost : 0.001 \n",
      "Step : 53 \n",
      "Cost : 0.001 \n",
      "Step : 54 \n",
      "Cost : 0.001 \n",
      "Step : 55 \n",
      "Cost : 0.001 \n",
      "Step : 56 \n",
      "Cost : 0.001 \n",
      "Step : 57 \n",
      "Cost : 0.001 \n",
      "Step : 58 \n",
      "Cost : 0.001 \n",
      "Step : 59 \n",
      "Cost : 0.001 \n",
      "Step : 60 \n",
      "Cost : 0.001 \n",
      "Step : 61 \n",
      "Cost : 0.001 \n",
      "Step : 62 \n",
      "Cost : 0.001 \n",
      "Step : 63 \n",
      "Cost : 0.001 \n",
      "Step : 64 \n",
      "Cost : 0.001 \n",
      "Step : 65 \n",
      "Cost : 0.001 \n",
      "Step : 66 \n",
      "Cost : 0.000 \n",
      "Step : 67 \n",
      "Cost : 0.000 \n",
      "Step : 68 \n",
      "Cost : 0.000 \n",
      "Step : 69 \n",
      "Cost : 0.000 \n",
      "Step : 70 \n",
      "Cost : 0.000 \n",
      "Step : 71 \n",
      "Cost : 0.000 \n",
      "Step : 72 \n",
      "Cost : 0.000 \n",
      "Step : 73 \n",
      "Cost : 0.000 \n",
      "Step : 74 \n",
      "Cost : 0.000 \n",
      "Step : 75 \n",
      "Cost : 0.000 \n",
      "Step : 76 \n",
      "Cost : 0.000 \n",
      "Step : 77 \n",
      "Cost : 0.000 \n",
      "Step : 78 \n",
      "Cost : 0.000 \n",
      "Step : 79 \n",
      "Cost : 0.000 \n",
      "Step : 80 \n",
      "Cost : 0.000 \n",
      "Step : 81 \n",
      "Cost : 0.000 \n",
      "Step : 82 \n",
      "Cost : 0.000 \n",
      "Step : 83 \n",
      "Cost : 0.000 \n",
      "Step : 84 \n",
      "Cost : 0.000 \n",
      "Step : 85 \n",
      "Cost : 0.000 \n",
      "Step : 86 \n",
      "Cost : 0.000 \n",
      "Step : 87 \n",
      "Cost : 0.000 \n",
      "Step : 88 \n",
      "Cost : 0.000 \n",
      "Step : 89 \n",
      "Cost : 0.000 \n",
      "Step : 90 \n",
      "Cost : 0.000 \n",
      "Step : 91 \n",
      "Cost : 0.000 \n",
      "Step : 92 \n",
      "Cost : 0.000 \n",
      "Step : 93 \n",
      "Cost : 0.000 \n",
      "Step : 94 \n",
      "Cost : 0.000 \n",
      "Step : 95 \n",
      "Cost : 0.000 \n",
      "Step : 96 \n",
      "Cost : 0.000 \n",
      "Step : 97 \n",
      "Cost : 0.000 \n",
      "Step : 98 \n",
      "Cost : 0.000 \n",
      "Step : 99 \n",
      "Cost : 0.000 \n",
      "Step : 100 \n",
      "Cost : 0.000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/6/ckpt-100'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X:x_data, Y:y_data})\n",
    "    \n",
    "    print('Step : %d ' % sess.run(global_step))\n",
    "    print('Cost : %.3f ' % sess.run(cost, feed_dict={X: x_data, Y:y_data}))\n",
    "    \n",
    "    # 텐서를 수집하고 저장함\n",
    "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "\n",
    "saver.save(sess, './model/6/ckpt', global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도 : 100.00\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도 : %.2f' % sess.run(accuracy*100, feed_dict = {X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
